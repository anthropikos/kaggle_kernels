{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "# Load from Hub ðŸ”¥\n",
    "model = timm.create_model(\n",
    "    'hf-hub:nateraw/resnet50-oxford-iiit-pet',\n",
    "    pretrained=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Sphynx', 'score': 0.03502282500267029},\n",
      " {'label': 'yorkshire_terrier', 'score': 0.034654807299375534},\n",
      " {'label': 'Russian_Blue', 'score': 0.0316169299185276},\n",
      " {'label': 'english_cocker_spaniel', 'score': 0.031417421996593475},\n",
      " {'label': 'german_shorthaired', 'score': 0.03130706399679184}]\n"
     ]
    }
   ],
   "source": [
    "# Set model to eval mode for inference\n",
    "model.eval()\n",
    "\n",
    "# Create Transform\n",
    "transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))\n",
    "\n",
    "# Get the labels from the model config\n",
    "labels = model.pretrained_cfg['label_names']\n",
    "top_k = min(len(labels), 5)\n",
    "\n",
    "# Use your own image file here...\n",
    "image_path = Path.home() / Path(\"Downloads/boxer.jpg\")\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Process PIL image with transforms and add a batch dimension\n",
    "x = transform(image).unsqueeze(0)\n",
    "\n",
    "# Pass inputs to model forward function to get outputs\n",
    "out = model(x)\n",
    "\n",
    "# Apply softmax to get predicted probabilities for each class\n",
    "probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "\n",
    "# Grab the values and indices of top 5 predicted classes\n",
    "values, indices = torch.topk(probabilities, top_k)\n",
    "\n",
    "# Prepare a nice dict of top k predictions\n",
    "predictions = [\n",
    "    {\"label\": labels[i], \"score\": v.item()}\n",
    "    for i, v in zip(indices, values)\n",
    "]\n",
    "pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model('vgg16.tv_in1k', pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VGG' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch-mps/lib/python3.13/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VGG' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "model.config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
